{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MediaPipe setup\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional Encoding for Transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model for pose classification\n",
    "class PoseTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, num_exercises, num_heads=8, num_layers=4, dim_feedforward=512, dropout=0.1):\n",
    "        super(PoseTransformer, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, 128)\n",
    "        self.pos_encoder = PositionalEncoding(128)\n",
    "        encoder_layers = nn.TransformerEncoderLayer(d_model=128, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers)\n",
    "        self.fc1 = nn.Linear(128, 64)\n",
    "        self.fc2 = nn.Linear(64, num_exercises)\n",
    "        self.fc3 = nn.Linear(64, 2)  # 2 classes for each exercise (terminal positions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x = x.mean(dim=0)  # Global average pooling\n",
    "        x = self.fc1(x)\n",
    "        exercise_type = self.fc2(x)\n",
    "        position = self.fc3(x)\n",
    "        return exercise_type, position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate angle between three points\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    c = np.array(c)\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get joint angles and landmarks\n",
    "def get_joint_angles(landmarks):\n",
    "    angles = []\n",
    "    for lm in landmarks:\n",
    "        angles.append([lm.x, lm.y, lm.z])\n",
    "    return np.array(angles).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise state class\n",
    "class ExerciseState:\n",
    "    def __init__(self):\n",
    "        self.count = 0\n",
    "        self.stage = None\n",
    "        self.previous_stage = None\n",
    "\n",
    "    def update(self, current_stage):\n",
    "        if current_stage != self.previous_stage:\n",
    "            if current_stage == \"End\" and self.previous_stage == \"Start\":\n",
    "                self.count += 1\n",
    "            self.stage = current_stage\n",
    "            self.previous_stage = current_stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function \n",
    "def main():\n",
    "    # Initialize pose estimation model\n",
    "    pose = mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "    # Initialize PoseTransformer model (you'll need to load your trained weights here)\n",
    "    input_dim = 99  # Adjust based on your model\n",
    "    num_exercises = 5  # Push-up, Pull-up, Sit-up, Jumping Jack, Squat\n",
    "    model = PoseTransformer(input_dim=input_dim, num_exercises=num_exercises)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Exercise names and states\n",
    "    exercise_names = ['Push-up', 'Pull-up', 'Sit-up', 'Jumping Jack', 'Squat']\n",
    "    exercise_states = {name: ExerciseState() for name in exercise_names}\n",
    "\n",
    "    # Open webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # For smoothing predictions\n",
    "    prediction_history = []\n",
    "    smoothing_window = 5\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Convert the BGR image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "            # Get joint angles\n",
    "            angles = get_joint_angles(landmarks)\n",
    "\n",
    "            # Predict exercise type and position\n",
    "            with torch.no_grad():\n",
    "                angles_tensor = torch.tensor(angles, dtype=torch.float32).unsqueeze(0)\n",
    "                exercise_type, position = model(angles_tensor)\n",
    "                predicted_exercise = torch.argmax(exercise_type, dim=0).item()\n",
    "                predicted_position = torch.argmax(position, dim=0).item()\n",
    "\n",
    "            # Smooth predictions\n",
    "            prediction_history.append((predicted_exercise, predicted_position))\n",
    "            if len(prediction_history) > smoothing_window:\n",
    "                prediction_history.pop(0)\n",
    "            \n",
    "            smoothed_exercise = max(set([p[0] for p in prediction_history]), key=[p[0] for p in prediction_history].count)\n",
    "            smoothed_position = max(set([p[1] for p in prediction_history]), key=[p[1] for p in prediction_history].count)\n",
    "\n",
    "            # Update exercise state\n",
    "            exercise_name = exercise_names[smoothed_exercise]\n",
    "            position_name = \"Start\" if smoothed_position == 0 else \"End\"\n",
    "            exercise_states[exercise_name].update(position_name)\n",
    "\n",
    "            # Draw skeleton\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "\n",
    "            # Display exercise, position, and count\n",
    "            cv2.putText(image, f\"{exercise_name}: {position_name}\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(image, f\"Count: {exercise_states[exercise_name].count}\", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            # Exercise-specific angle calculations and feedback\n",
    "            if exercise_name == 'Push-up':\n",
    "                shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x, landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "                elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "                wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x, landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "                elbow_angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                cv2.putText(image, f\"Elbow Angle: {int(elbow_angle)}\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                \n",
    "                if position_name == \"End\" and elbow_angle > 90:\n",
    "                    cv2.putText(image, \"Go lower!\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            elif exercise_name == 'Squat':\n",
    "                hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x, landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]\n",
    "                knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]\n",
    "                ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x, landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]\n",
    "                knee_angle = calculate_angle(hip, knee, ankle)\n",
    "                cv2.putText(image, f\"Knee Angle: {int(knee_angle)}\", (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                \n",
    "                if position_name == \"End\" and knee_angle < 90:\n",
    "                    cv2.putText(image, \"Squat deeper!\", (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "            # Add similar angle calculations and feedback for other exercises\n",
    "\n",
    "        cv2.imshow('Exercise Pose Correction', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
